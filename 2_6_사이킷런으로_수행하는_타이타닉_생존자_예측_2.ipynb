{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "id": "zrJqruAEsfBA",
    "outputId": "aec74259-fb99-4dbd-e695-94c7acf74201"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>PassengerId</th>\n",
       "      <th>Survived</th>\n",
       "      <th>Pclass</th>\n",
       "      <th>Name</th>\n",
       "      <th>Sex</th>\n",
       "      <th>Age</th>\n",
       "      <th>SibSp</th>\n",
       "      <th>Parch</th>\n",
       "      <th>Ticket</th>\n",
       "      <th>Fare</th>\n",
       "      <th>Cabin</th>\n",
       "      <th>Embarked</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>Braund, Mr. Owen Harris</td>\n",
       "      <td>male</td>\n",
       "      <td>22.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>A/5 21171</td>\n",
       "      <td>7.2500</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>Cumings, Mrs. John Bradley (Florence Briggs Th...</td>\n",
       "      <td>female</td>\n",
       "      <td>38.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>PC 17599</td>\n",
       "      <td>71.2833</td>\n",
       "      <td>C85</td>\n",
       "      <td>C</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>Heikkinen, Miss. Laina</td>\n",
       "      <td>female</td>\n",
       "      <td>26.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>STON/O2. 3101282</td>\n",
       "      <td>7.9250</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   PassengerId  Survived  Pclass  \\\n",
       "0            1         0       3   \n",
       "1            2         1       1   \n",
       "2            3         1       3   \n",
       "\n",
       "                                                Name     Sex   Age  SibSp  \\\n",
       "0                            Braund, Mr. Owen Harris    male  22.0      1   \n",
       "1  Cumings, Mrs. John Bradley (Florence Briggs Th...  female  38.0      1   \n",
       "2                             Heikkinen, Miss. Laina  female  26.0      0   \n",
       "\n",
       "   Parch            Ticket     Fare Cabin Embarked  \n",
       "0      0         A/5 21171   7.2500   NaN        S  \n",
       "1      0          PC 17599  71.2833   C85        C  \n",
       "2      0  STON/O2. 3101282   7.9250   NaN        S  "
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "%matplotlib inline\n",
    "\n",
    "titanic_df = pd.read_csv('data/titanic_train.csv')\n",
    "titanic_df.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "id": "MbYg9LhmsfBC",
    "outputId": "d1ab89d4-c059-4340-d3a1-d09a82d73217"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " ### train 데이터 정보 ###  \n",
      "\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 891 entries, 0 to 890\n",
      "Data columns (total 12 columns):\n",
      " #   Column       Non-Null Count  Dtype  \n",
      "---  ------       --------------  -----  \n",
      " 0   PassengerId  891 non-null    int64  \n",
      " 1   Survived     891 non-null    int64  \n",
      " 2   Pclass       891 non-null    int64  \n",
      " 3   Name         891 non-null    object \n",
      " 4   Sex          891 non-null    object \n",
      " 5   Age          714 non-null    float64\n",
      " 6   SibSp        891 non-null    int64  \n",
      " 7   Parch        891 non-null    int64  \n",
      " 8   Ticket       891 non-null    object \n",
      " 9   Fare         891 non-null    float64\n",
      " 10  Cabin        204 non-null    object \n",
      " 11  Embarked     889 non-null    object \n",
      "dtypes: float64(2), int64(5), object(5)\n",
      "memory usage: 83.7+ KB\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "print('\\n ### train 데이터 정보 ###  \\n')\n",
    "print(titanic_df.info())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "id": "-zHclzY-sfBD",
    "outputId": "4e166028-f2b1-41c6-af6c-f35fa87e7a3e"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "데이터 세트 Null 값 갯수  0\n"
     ]
    }
   ],
   "source": [
    "titanic_df['Age'].fillna(titanic_df['Age'].mean(),inplace=True)\n",
    "titanic_df['Cabin'].fillna('N',inplace=True)\n",
    "titanic_df['Embarked'].fillna('N',inplace=True)\n",
    "print('데이터 세트 Null 값 갯수 ',titanic_df.isnull().sum().sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "id": "edOvfMb_sfBE",
    "outputId": "40a619c0-5bad-4c47-88e3-8f363243e7d3"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Sex 값 분포 :\n",
      " male      577\n",
      "female    314\n",
      "Name: Sex, dtype: int64\n",
      "\n",
      " Cabin 값 분포 :\n",
      " N              687\n",
      "C23 C25 C27      4\n",
      "G6               4\n",
      "B96 B98          4\n",
      "C22 C26          3\n",
      "              ... \n",
      "E34              1\n",
      "C7               1\n",
      "C54              1\n",
      "E36              1\n",
      "C148             1\n",
      "Name: Cabin, Length: 148, dtype: int64\n",
      "\n",
      " Embarked 값 분포 :\n",
      " S    644\n",
      "C    168\n",
      "Q     77\n",
      "N      2\n",
      "Name: Embarked, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "print(' Sex 값 분포 :\\n',titanic_df['Sex'].value_counts())\n",
    "print('\\n Cabin 값 분포 :\\n',titanic_df['Cabin'].value_counts())\n",
    "print('\\n Embarked 값 분포 :\\n',titanic_df['Embarked'].value_counts())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "id": "3qplJvTfsfBF",
    "outputId": "da93c0a5-e0a5-4ea4-dbdf-55116450efd4"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0    N\n",
      "1    C\n",
      "2    N\n",
      "Name: Cabin, dtype: object\n"
     ]
    }
   ],
   "source": [
    "titanic_df['Cabin'] = titanic_df['Cabin'].str[:1]\n",
    "print(titanic_df['Cabin'].head(3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "id": "wQRSsM24sfBF",
    "outputId": "728d60b0-3f08-4b57-973d-6cb8b05796fd"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Sex     Survived\n",
       "female  0            81\n",
       "        1           233\n",
       "male    0           468\n",
       "        1           109\n",
       "Name: Survived, dtype: int64"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "titanic_df.groupby(['Sex','Survived'])['Survived'].count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "id": "I97bGQohsfBG",
    "outputId": "65e7c800-cf8c-40f9-8db5-67a225a2ceaa",
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<AxesSubplot:xlabel='Sex', ylabel='Survived'>"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "sns.barplot(x='Sex', y = 'Survived', data=titanic_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "id": "38uS_Lf8sfBG",
    "outputId": "ddf07acf-2aeb-4806-cfee-e319eee8ede7"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<AxesSubplot:xlabel='Pclass', ylabel='Survived'>"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "sns.barplot(x='Pclass', y='Survived', hue='Sex', data=titanic_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "id": "kP6VIkqVsfBH",
    "outputId": "1b85a74c-b1ab-47e3-e774-c396844e8624"
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 720x432 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# 입력 age에 따라 구분값을 반환하는 함수 설정. DataFrame의 apply lambda식에 사용. \n",
    "def get_category(age):\n",
    "    cat = ''\n",
    "    if age <= -1: cat = 'Unknown'\n",
    "    elif age <= 5: cat = 'Baby'\n",
    "    elif age <= 12: cat = 'Child'\n",
    "    elif age <= 18: cat = 'Teenager'\n",
    "    elif age <= 25: cat = 'Student'\n",
    "    elif age <= 35: cat = 'Young Adult'\n",
    "    elif age <= 60: cat = 'Adult'\n",
    "    else : cat = 'Elderly'\n",
    "    \n",
    "    return cat\n",
    "\n",
    "# 막대그래프의 크기 figure를 더 크게 설정 \n",
    "plt.figure(figsize=(10,6))\n",
    "\n",
    "#X축의 값을 순차적으로 표시하기 위한 설정 \n",
    "group_names = ['Unknown', 'Baby', 'Child', 'Teenager', 'Student', 'Young Adult', 'Adult', 'Elderly']\n",
    "\n",
    "# lambda 식에 위에서 생성한 get_category( ) 함수를 반환값으로 지정. \n",
    "# get_category(X)는 입력값으로 'Age' 컬럼값을 받아서 해당하는 cat 반환\n",
    "titanic_df['Age_cat'] = titanic_df['Age'].apply(lambda x : get_category(x))\n",
    "sns.barplot(x='Age_cat', y = 'Survived', hue='Sex', data=titanic_df, order=group_names)\n",
    "titanic_df.drop('Age_cat', axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "id": "KLMVw-aFsfBI",
    "outputId": "aba59c91-afb2-4802-c903-f6467f0ac099"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>PassengerId</th>\n",
       "      <th>Survived</th>\n",
       "      <th>Pclass</th>\n",
       "      <th>Name</th>\n",
       "      <th>Sex</th>\n",
       "      <th>Age</th>\n",
       "      <th>SibSp</th>\n",
       "      <th>Parch</th>\n",
       "      <th>Ticket</th>\n",
       "      <th>Fare</th>\n",
       "      <th>Cabin</th>\n",
       "      <th>Embarked</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>Braund, Mr. Owen Harris</td>\n",
       "      <td>1</td>\n",
       "      <td>22.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>A/5 21171</td>\n",
       "      <td>7.2500</td>\n",
       "      <td>7</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>Cumings, Mrs. John Bradley (Florence Briggs Th...</td>\n",
       "      <td>0</td>\n",
       "      <td>38.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>PC 17599</td>\n",
       "      <td>71.2833</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>Heikkinen, Miss. Laina</td>\n",
       "      <td>0</td>\n",
       "      <td>26.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>STON/O2. 3101282</td>\n",
       "      <td>7.9250</td>\n",
       "      <td>7</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>Futrelle, Mrs. Jacques Heath (Lily May Peel)</td>\n",
       "      <td>0</td>\n",
       "      <td>35.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>113803</td>\n",
       "      <td>53.1000</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>Allen, Mr. William Henry</td>\n",
       "      <td>1</td>\n",
       "      <td>35.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>373450</td>\n",
       "      <td>8.0500</td>\n",
       "      <td>7</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   PassengerId  Survived  Pclass  \\\n",
       "0            1         0       3   \n",
       "1            2         1       1   \n",
       "2            3         1       3   \n",
       "3            4         1       1   \n",
       "4            5         0       3   \n",
       "\n",
       "                                                Name  Sex   Age  SibSp  Parch  \\\n",
       "0                            Braund, Mr. Owen Harris    1  22.0      1      0   \n",
       "1  Cumings, Mrs. John Bradley (Florence Briggs Th...    0  38.0      1      0   \n",
       "2                             Heikkinen, Miss. Laina    0  26.0      0      0   \n",
       "3       Futrelle, Mrs. Jacques Heath (Lily May Peel)    0  35.0      1      0   \n",
       "4                           Allen, Mr. William Henry    1  35.0      0      0   \n",
       "\n",
       "             Ticket     Fare  Cabin  Embarked  \n",
       "0         A/5 21171   7.2500      7         3  \n",
       "1          PC 17599  71.2833      2         0  \n",
       "2  STON/O2. 3101282   7.9250      7         3  \n",
       "3            113803  53.1000      2         3  \n",
       "4            373450   8.0500      7         3  "
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn import preprocessing\n",
    "\n",
    "def encode_features(dataDF):\n",
    "    features = ['Cabin', 'Sex', 'Embarked']\n",
    "    for feature in features:\n",
    "        le = preprocessing.LabelEncoder()\n",
    "        le = le.fit(dataDF[feature])\n",
    "        dataDF[feature] = le.transform(dataDF[feature])\n",
    "        \n",
    "    return dataDF\n",
    "\n",
    "titanic_df = encode_features(titanic_df)\n",
    "titanic_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "id": "vSYVL2kssfBJ"
   },
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "# Null 처리 함수\n",
    "def fillna(df):\n",
    "    df['Age'].fillna(df['Age'].mean(),inplace=True)\n",
    "    df['Cabin'].fillna('N',inplace=True)\n",
    "    df['Embarked'].fillna('N',inplace=True)\n",
    "    df['Fare'].fillna(0,inplace=True)\n",
    "    return df\n",
    "\n",
    "# 머신러닝 알고리즘에 불필요한 속성 제거\n",
    "def drop_features(df):\n",
    "    df.drop(['PassengerId','Name','Ticket'],axis=1,inplace=True)\n",
    "    return df\n",
    "\n",
    "# 레이블 인코딩 수행. \n",
    "def format_features(df):\n",
    "    df['Cabin'] = df['Cabin'].str[:1]\n",
    "    features = ['Cabin','Sex','Embarked']\n",
    "    for feature in features:\n",
    "        le = LabelEncoder()\n",
    "        le = le.fit(df[feature])\n",
    "        df[feature] = le.transform(df[feature])\n",
    "    return df\n",
    "\n",
    "# 앞에서 설정한 Data Preprocessing 함수 호출\n",
    "def transform_features(df):\n",
    "    df = fillna(df)\n",
    "    df = drop_features(df)\n",
    "    df = format_features(df)\n",
    "    return df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "id": "8fIEyqiNsfBJ"
   },
   "outputs": [],
   "source": [
    "# 원본 데이터를 재로딩 하고, feature데이터 셋과 Label 데이터 셋 추출. \n",
    "titanic_df = pd.read_csv('data/titanic_train.csv')\n",
    "y_titanic_df = titanic_df['Survived']\n",
    "X_titanic_df= titanic_df.drop('Survived',axis=1)\n",
    "\n",
    "X_titanic_df = transform_features(X_titanic_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Pclass</th>\n",
       "      <th>Sex</th>\n",
       "      <th>Age</th>\n",
       "      <th>SibSp</th>\n",
       "      <th>Parch</th>\n",
       "      <th>Fare</th>\n",
       "      <th>Cabin</th>\n",
       "      <th>Embarked</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>22.000000</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>7.2500</td>\n",
       "      <td>7</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>38.000000</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>71.2833</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>26.000000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>7.9250</td>\n",
       "      <td>7</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>35.000000</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>53.1000</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>35.000000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>8.0500</td>\n",
       "      <td>7</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>886</th>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>27.000000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>13.0000</td>\n",
       "      <td>7</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>887</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>19.000000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>30.0000</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>888</th>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>29.699118</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>23.4500</td>\n",
       "      <td>7</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>889</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>26.000000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>30.0000</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>890</th>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>32.000000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>7.7500</td>\n",
       "      <td>7</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>891 rows × 8 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     Pclass  Sex        Age  SibSp  Parch     Fare  Cabin  Embarked\n",
       "0         3    1  22.000000      1      0   7.2500      7         3\n",
       "1         1    0  38.000000      1      0  71.2833      2         0\n",
       "2         3    0  26.000000      0      0   7.9250      7         3\n",
       "3         1    0  35.000000      1      0  53.1000      2         3\n",
       "4         3    1  35.000000      0      0   8.0500      7         3\n",
       "..      ...  ...        ...    ...    ...      ...    ...       ...\n",
       "886       2    1  27.000000      0      0  13.0000      7         3\n",
       "887       1    0  19.000000      0      0  30.0000      1         3\n",
       "888       3    0  29.699118      1      2  23.4500      7         3\n",
       "889       1    1  26.000000      0      0  30.0000      2         0\n",
       "890       3    1  32.000000      0      0   7.7500      7         2\n",
       "\n",
       "[891 rows x 8 columns]"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_titanic_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "id": "YBZUpaWzsfBK"
   },
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, y_train, y_test=train_test_split(X_titanic_df, y_titanic_df, \\\n",
    "                                                  test_size=0.2, random_state=11)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "id": "izTJtRblsfBK",
    "outputId": "33b742a9-02d3-48a3-8671-d39f1f7dd0c1"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DecisionTreeClassifier 정확도: 0.7877\n",
      "RandomForestClassifier 정확도:0.8547\n",
      "LogisticRegression 정확도: 0.8492\n",
      "SVM 정확도: 0.8492\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:763: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    }
   ],
   "source": [
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "# 결정트리, Random Forest, 로지스틱 회귀를 위한 사이킷런 Classifier 클래스 생성\n",
    "dt_clf = DecisionTreeClassifier(random_state=11)\n",
    "rf_clf = RandomForestClassifier(random_state=11)\n",
    "lr_clf = LogisticRegression()\n",
    "svm_svc = SVC() ##추가해보자.!!\n",
    "\n",
    "# DecisionTreeClassifier 학습/예측/평가\n",
    "dt_clf.fit(X_train , y_train)\n",
    "dt_pred = dt_clf.predict(X_test)\n",
    "print('DecisionTreeClassifier 정확도: {0:.4f}'.format(accuracy_score(y_test, dt_pred)))\n",
    "\n",
    "# RandomForestClassifier 학습/예측/평가\n",
    "rf_clf.fit(X_train , y_train)\n",
    "rf_pred = rf_clf.predict(X_test)\n",
    "print('RandomForestClassifier 정확도:{0:.4f}'.format(accuracy_score(y_test, rf_pred)))\n",
    "\n",
    "# LogisticRegression 학습/예측/평가\n",
    "lr_clf.fit(X_train , y_train)\n",
    "lr_pred = lr_clf.predict(X_test)\n",
    "print('LogisticRegression 정확도: {0:.4f}'.format(accuracy_score(y_test, lr_pred)))\n",
    "\n",
    "\n",
    "# SVM 학습/예측/평가\n",
    "svm_svc.fit(X_train , y_train)\n",
    "svm_pred = lr_clf.predict(X_test)\n",
    "print('SVM 정확도: {0:.4f}'.format(accuracy_score(y_test, lr_pred)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import KFold"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "kfold = KFold(n_splits = 5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n"
     ]
    }
   ],
   "source": [
    "for iter_count, (train_index, test_index) in enumerate(kfold.split(X_titanic_df)):\n",
    "    print(iter_count)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(891, 8)"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_titanic_df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "[179 180 181 182 183 184 185 186 187 188 189 190 191 192 193 194 195 196\n",
      " 197 198 199 200 201 202 203 204 205 206 207 208 209 210 211 212 213 214\n",
      " 215 216 217 218 219 220 221 222 223 224 225 226 227 228 229 230 231 232\n",
      " 233 234 235 236 237 238 239 240 241 242 243 244 245 246 247 248 249 250\n",
      " 251 252 253 254 255 256 257 258 259 260 261 262 263 264 265 266 267 268\n",
      " 269 270 271 272 273 274 275 276 277 278 279 280 281 282 283 284 285 286\n",
      " 287 288 289 290 291 292 293 294 295 296 297 298 299 300 301 302 303 304\n",
      " 305 306 307 308 309 310 311 312 313 314 315 316 317 318 319 320 321 322\n",
      " 323 324 325 326 327 328 329 330 331 332 333 334 335 336 337 338 339 340\n",
      " 341 342 343 344 345 346 347 348 349 350 351 352 353 354 355 356 357 358\n",
      " 359 360 361 362 363 364 365 366 367 368 369 370 371 372 373 374 375 376\n",
      " 377 378 379 380 381 382 383 384 385 386 387 388 389 390 391 392 393 394\n",
      " 395 396 397 398 399 400 401 402 403 404 405 406 407 408 409 410 411 412\n",
      " 413 414 415 416 417 418 419 420 421 422 423 424 425 426 427 428 429 430\n",
      " 431 432 433 434 435 436 437 438 439 440 441 442 443 444 445 446 447 448\n",
      " 449 450 451 452 453 454 455 456 457 458 459 460 461 462 463 464 465 466\n",
      " 467 468 469 470 471 472 473 474 475 476 477 478 479 480 481 482 483 484\n",
      " 485 486 487 488 489 490 491 492 493 494 495 496 497 498 499 500 501 502\n",
      " 503 504 505 506 507 508 509 510 511 512 513 514 515 516 517 518 519 520\n",
      " 521 522 523 524 525 526 527 528 529 530 531 532 533 534 535 536 537 538\n",
      " 539 540 541 542 543 544 545 546 547 548 549 550 551 552 553 554 555 556\n",
      " 557 558 559 560 561 562 563 564 565 566 567 568 569 570 571 572 573 574\n",
      " 575 576 577 578 579 580 581 582 583 584 585 586 587 588 589 590 591 592\n",
      " 593 594 595 596 597 598 599 600 601 602 603 604 605 606 607 608 609 610\n",
      " 611 612 613 614 615 616 617 618 619 620 621 622 623 624 625 626 627 628\n",
      " 629 630 631 632 633 634 635 636 637 638 639 640 641 642 643 644 645 646\n",
      " 647 648 649 650 651 652 653 654 655 656 657 658 659 660 661 662 663 664\n",
      " 665 666 667 668 669 670 671 672 673 674 675 676 677 678 679 680 681 682\n",
      " 683 684 685 686 687 688 689 690 691 692 693 694 695 696 697 698 699 700\n",
      " 701 702 703 704 705 706 707 708 709 710 711 712 713 714 715 716 717 718\n",
      " 719 720 721 722 723 724 725 726 727 728 729 730 731 732 733 734 735 736\n",
      " 737 738 739 740 741 742 743 744 745 746 747 748 749 750 751 752 753 754\n",
      " 755 756 757 758 759 760 761 762 763 764 765 766 767 768 769 770 771 772\n",
      " 773 774 775 776 777 778 779 780 781 782 783 784 785 786 787 788 789 790\n",
      " 791 792 793 794 795 796 797 798 799 800 801 802 803 804 805 806 807 808\n",
      " 809 810 811 812 813 814 815 816 817 818 819 820 821 822 823 824 825 826\n",
      " 827 828 829 830 831 832 833 834 835 836 837 838 839 840 841 842 843 844\n",
      " 845 846 847 848 849 850 851 852 853 854 855 856 857 858 859 860 861 862\n",
      " 863 864 865 866 867 868 869 870 871 872 873 874 875 876 877 878 879 880\n",
      " 881 882 883 884 885 886 887 888 889 890]\n",
      "[  0   1   2   3   4   5   6   7   8   9  10  11  12  13  14  15  16  17\n",
      "  18  19  20  21  22  23  24  25  26  27  28  29  30  31  32  33  34  35\n",
      "  36  37  38  39  40  41  42  43  44  45  46  47  48  49  50  51  52  53\n",
      "  54  55  56  57  58  59  60  61  62  63  64  65  66  67  68  69  70  71\n",
      "  72  73  74  75  76  77  78  79  80  81  82  83  84  85  86  87  88  89\n",
      "  90  91  92  93  94  95  96  97  98  99 100 101 102 103 104 105 106 107\n",
      " 108 109 110 111 112 113 114 115 116 117 118 119 120 121 122 123 124 125\n",
      " 126 127 128 129 130 131 132 133 134 135 136 137 138 139 140 141 142 143\n",
      " 144 145 146 147 148 149 150 151 152 153 154 155 156 157 158 159 160 161\n",
      " 162 163 164 165 166 167 168 169 170 171 172 173 174 175 176 177 178]\n",
      "1\n",
      "[  0   1   2   3   4   5   6   7   8   9  10  11  12  13  14  15  16  17\n",
      "  18  19  20  21  22  23  24  25  26  27  28  29  30  31  32  33  34  35\n",
      "  36  37  38  39  40  41  42  43  44  45  46  47  48  49  50  51  52  53\n",
      "  54  55  56  57  58  59  60  61  62  63  64  65  66  67  68  69  70  71\n",
      "  72  73  74  75  76  77  78  79  80  81  82  83  84  85  86  87  88  89\n",
      "  90  91  92  93  94  95  96  97  98  99 100 101 102 103 104 105 106 107\n",
      " 108 109 110 111 112 113 114 115 116 117 118 119 120 121 122 123 124 125\n",
      " 126 127 128 129 130 131 132 133 134 135 136 137 138 139 140 141 142 143\n",
      " 144 145 146 147 148 149 150 151 152 153 154 155 156 157 158 159 160 161\n",
      " 162 163 164 165 166 167 168 169 170 171 172 173 174 175 176 177 178 357\n",
      " 358 359 360 361 362 363 364 365 366 367 368 369 370 371 372 373 374 375\n",
      " 376 377 378 379 380 381 382 383 384 385 386 387 388 389 390 391 392 393\n",
      " 394 395 396 397 398 399 400 401 402 403 404 405 406 407 408 409 410 411\n",
      " 412 413 414 415 416 417 418 419 420 421 422 423 424 425 426 427 428 429\n",
      " 430 431 432 433 434 435 436 437 438 439 440 441 442 443 444 445 446 447\n",
      " 448 449 450 451 452 453 454 455 456 457 458 459 460 461 462 463 464 465\n",
      " 466 467 468 469 470 471 472 473 474 475 476 477 478 479 480 481 482 483\n",
      " 484 485 486 487 488 489 490 491 492 493 494 495 496 497 498 499 500 501\n",
      " 502 503 504 505 506 507 508 509 510 511 512 513 514 515 516 517 518 519\n",
      " 520 521 522 523 524 525 526 527 528 529 530 531 532 533 534 535 536 537\n",
      " 538 539 540 541 542 543 544 545 546 547 548 549 550 551 552 553 554 555\n",
      " 556 557 558 559 560 561 562 563 564 565 566 567 568 569 570 571 572 573\n",
      " 574 575 576 577 578 579 580 581 582 583 584 585 586 587 588 589 590 591\n",
      " 592 593 594 595 596 597 598 599 600 601 602 603 604 605 606 607 608 609\n",
      " 610 611 612 613 614 615 616 617 618 619 620 621 622 623 624 625 626 627\n",
      " 628 629 630 631 632 633 634 635 636 637 638 639 640 641 642 643 644 645\n",
      " 646 647 648 649 650 651 652 653 654 655 656 657 658 659 660 661 662 663\n",
      " 664 665 666 667 668 669 670 671 672 673 674 675 676 677 678 679 680 681\n",
      " 682 683 684 685 686 687 688 689 690 691 692 693 694 695 696 697 698 699\n",
      " 700 701 702 703 704 705 706 707 708 709 710 711 712 713 714 715 716 717\n",
      " 718 719 720 721 722 723 724 725 726 727 728 729 730 731 732 733 734 735\n",
      " 736 737 738 739 740 741 742 743 744 745 746 747 748 749 750 751 752 753\n",
      " 754 755 756 757 758 759 760 761 762 763 764 765 766 767 768 769 770 771\n",
      " 772 773 774 775 776 777 778 779 780 781 782 783 784 785 786 787 788 789\n",
      " 790 791 792 793 794 795 796 797 798 799 800 801 802 803 804 805 806 807\n",
      " 808 809 810 811 812 813 814 815 816 817 818 819 820 821 822 823 824 825\n",
      " 826 827 828 829 830 831 832 833 834 835 836 837 838 839 840 841 842 843\n",
      " 844 845 846 847 848 849 850 851 852 853 854 855 856 857 858 859 860 861\n",
      " 862 863 864 865 866 867 868 869 870 871 872 873 874 875 876 877 878 879\n",
      " 880 881 882 883 884 885 886 887 888 889 890]\n",
      "[179 180 181 182 183 184 185 186 187 188 189 190 191 192 193 194 195 196\n",
      " 197 198 199 200 201 202 203 204 205 206 207 208 209 210 211 212 213 214\n",
      " 215 216 217 218 219 220 221 222 223 224 225 226 227 228 229 230 231 232\n",
      " 233 234 235 236 237 238 239 240 241 242 243 244 245 246 247 248 249 250\n",
      " 251 252 253 254 255 256 257 258 259 260 261 262 263 264 265 266 267 268\n",
      " 269 270 271 272 273 274 275 276 277 278 279 280 281 282 283 284 285 286\n",
      " 287 288 289 290 291 292 293 294 295 296 297 298 299 300 301 302 303 304\n",
      " 305 306 307 308 309 310 311 312 313 314 315 316 317 318 319 320 321 322\n",
      " 323 324 325 326 327 328 329 330 331 332 333 334 335 336 337 338 339 340\n",
      " 341 342 343 344 345 346 347 348 349 350 351 352 353 354 355 356]\n",
      "2\n",
      "[  0   1   2   3   4   5   6   7   8   9  10  11  12  13  14  15  16  17\n",
      "  18  19  20  21  22  23  24  25  26  27  28  29  30  31  32  33  34  35\n",
      "  36  37  38  39  40  41  42  43  44  45  46  47  48  49  50  51  52  53\n",
      "  54  55  56  57  58  59  60  61  62  63  64  65  66  67  68  69  70  71\n",
      "  72  73  74  75  76  77  78  79  80  81  82  83  84  85  86  87  88  89\n",
      "  90  91  92  93  94  95  96  97  98  99 100 101 102 103 104 105 106 107\n",
      " 108 109 110 111 112 113 114 115 116 117 118 119 120 121 122 123 124 125\n",
      " 126 127 128 129 130 131 132 133 134 135 136 137 138 139 140 141 142 143\n",
      " 144 145 146 147 148 149 150 151 152 153 154 155 156 157 158 159 160 161\n",
      " 162 163 164 165 166 167 168 169 170 171 172 173 174 175 176 177 178 179\n",
      " 180 181 182 183 184 185 186 187 188 189 190 191 192 193 194 195 196 197\n",
      " 198 199 200 201 202 203 204 205 206 207 208 209 210 211 212 213 214 215\n",
      " 216 217 218 219 220 221 222 223 224 225 226 227 228 229 230 231 232 233\n",
      " 234 235 236 237 238 239 240 241 242 243 244 245 246 247 248 249 250 251\n",
      " 252 253 254 255 256 257 258 259 260 261 262 263 264 265 266 267 268 269\n",
      " 270 271 272 273 274 275 276 277 278 279 280 281 282 283 284 285 286 287\n",
      " 288 289 290 291 292 293 294 295 296 297 298 299 300 301 302 303 304 305\n",
      " 306 307 308 309 310 311 312 313 314 315 316 317 318 319 320 321 322 323\n",
      " 324 325 326 327 328 329 330 331 332 333 334 335 336 337 338 339 340 341\n",
      " 342 343 344 345 346 347 348 349 350 351 352 353 354 355 356 535 536 537\n",
      " 538 539 540 541 542 543 544 545 546 547 548 549 550 551 552 553 554 555\n",
      " 556 557 558 559 560 561 562 563 564 565 566 567 568 569 570 571 572 573\n",
      " 574 575 576 577 578 579 580 581 582 583 584 585 586 587 588 589 590 591\n",
      " 592 593 594 595 596 597 598 599 600 601 602 603 604 605 606 607 608 609\n",
      " 610 611 612 613 614 615 616 617 618 619 620 621 622 623 624 625 626 627\n",
      " 628 629 630 631 632 633 634 635 636 637 638 639 640 641 642 643 644 645\n",
      " 646 647 648 649 650 651 652 653 654 655 656 657 658 659 660 661 662 663\n",
      " 664 665 666 667 668 669 670 671 672 673 674 675 676 677 678 679 680 681\n",
      " 682 683 684 685 686 687 688 689 690 691 692 693 694 695 696 697 698 699\n",
      " 700 701 702 703 704 705 706 707 708 709 710 711 712 713 714 715 716 717\n",
      " 718 719 720 721 722 723 724 725 726 727 728 729 730 731 732 733 734 735\n",
      " 736 737 738 739 740 741 742 743 744 745 746 747 748 749 750 751 752 753\n",
      " 754 755 756 757 758 759 760 761 762 763 764 765 766 767 768 769 770 771\n",
      " 772 773 774 775 776 777 778 779 780 781 782 783 784 785 786 787 788 789\n",
      " 790 791 792 793 794 795 796 797 798 799 800 801 802 803 804 805 806 807\n",
      " 808 809 810 811 812 813 814 815 816 817 818 819 820 821 822 823 824 825\n",
      " 826 827 828 829 830 831 832 833 834 835 836 837 838 839 840 841 842 843\n",
      " 844 845 846 847 848 849 850 851 852 853 854 855 856 857 858 859 860 861\n",
      " 862 863 864 865 866 867 868 869 870 871 872 873 874 875 876 877 878 879\n",
      " 880 881 882 883 884 885 886 887 888 889 890]\n",
      "[357 358 359 360 361 362 363 364 365 366 367 368 369 370 371 372 373 374\n",
      " 375 376 377 378 379 380 381 382 383 384 385 386 387 388 389 390 391 392\n",
      " 393 394 395 396 397 398 399 400 401 402 403 404 405 406 407 408 409 410\n",
      " 411 412 413 414 415 416 417 418 419 420 421 422 423 424 425 426 427 428\n",
      " 429 430 431 432 433 434 435 436 437 438 439 440 441 442 443 444 445 446\n",
      " 447 448 449 450 451 452 453 454 455 456 457 458 459 460 461 462 463 464\n",
      " 465 466 467 468 469 470 471 472 473 474 475 476 477 478 479 480 481 482\n",
      " 483 484 485 486 487 488 489 490 491 492 493 494 495 496 497 498 499 500\n",
      " 501 502 503 504 505 506 507 508 509 510 511 512 513 514 515 516 517 518\n",
      " 519 520 521 522 523 524 525 526 527 528 529 530 531 532 533 534]\n",
      "3\n",
      "[  0   1   2   3   4   5   6   7   8   9  10  11  12  13  14  15  16  17\n",
      "  18  19  20  21  22  23  24  25  26  27  28  29  30  31  32  33  34  35\n",
      "  36  37  38  39  40  41  42  43  44  45  46  47  48  49  50  51  52  53\n",
      "  54  55  56  57  58  59  60  61  62  63  64  65  66  67  68  69  70  71\n",
      "  72  73  74  75  76  77  78  79  80  81  82  83  84  85  86  87  88  89\n",
      "  90  91  92  93  94  95  96  97  98  99 100 101 102 103 104 105 106 107\n",
      " 108 109 110 111 112 113 114 115 116 117 118 119 120 121 122 123 124 125\n",
      " 126 127 128 129 130 131 132 133 134 135 136 137 138 139 140 141 142 143\n",
      " 144 145 146 147 148 149 150 151 152 153 154 155 156 157 158 159 160 161\n",
      " 162 163 164 165 166 167 168 169 170 171 172 173 174 175 176 177 178 179\n",
      " 180 181 182 183 184 185 186 187 188 189 190 191 192 193 194 195 196 197\n",
      " 198 199 200 201 202 203 204 205 206 207 208 209 210 211 212 213 214 215\n",
      " 216 217 218 219 220 221 222 223 224 225 226 227 228 229 230 231 232 233\n",
      " 234 235 236 237 238 239 240 241 242 243 244 245 246 247 248 249 250 251\n",
      " 252 253 254 255 256 257 258 259 260 261 262 263 264 265 266 267 268 269\n",
      " 270 271 272 273 274 275 276 277 278 279 280 281 282 283 284 285 286 287\n",
      " 288 289 290 291 292 293 294 295 296 297 298 299 300 301 302 303 304 305\n",
      " 306 307 308 309 310 311 312 313 314 315 316 317 318 319 320 321 322 323\n",
      " 324 325 326 327 328 329 330 331 332 333 334 335 336 337 338 339 340 341\n",
      " 342 343 344 345 346 347 348 349 350 351 352 353 354 355 356 357 358 359\n",
      " 360 361 362 363 364 365 366 367 368 369 370 371 372 373 374 375 376 377\n",
      " 378 379 380 381 382 383 384 385 386 387 388 389 390 391 392 393 394 395\n",
      " 396 397 398 399 400 401 402 403 404 405 406 407 408 409 410 411 412 413\n",
      " 414 415 416 417 418 419 420 421 422 423 424 425 426 427 428 429 430 431\n",
      " 432 433 434 435 436 437 438 439 440 441 442 443 444 445 446 447 448 449\n",
      " 450 451 452 453 454 455 456 457 458 459 460 461 462 463 464 465 466 467\n",
      " 468 469 470 471 472 473 474 475 476 477 478 479 480 481 482 483 484 485\n",
      " 486 487 488 489 490 491 492 493 494 495 496 497 498 499 500 501 502 503\n",
      " 504 505 506 507 508 509 510 511 512 513 514 515 516 517 518 519 520 521\n",
      " 522 523 524 525 526 527 528 529 530 531 532 533 534 713 714 715 716 717\n",
      " 718 719 720 721 722 723 724 725 726 727 728 729 730 731 732 733 734 735\n",
      " 736 737 738 739 740 741 742 743 744 745 746 747 748 749 750 751 752 753\n",
      " 754 755 756 757 758 759 760 761 762 763 764 765 766 767 768 769 770 771\n",
      " 772 773 774 775 776 777 778 779 780 781 782 783 784 785 786 787 788 789\n",
      " 790 791 792 793 794 795 796 797 798 799 800 801 802 803 804 805 806 807\n",
      " 808 809 810 811 812 813 814 815 816 817 818 819 820 821 822 823 824 825\n",
      " 826 827 828 829 830 831 832 833 834 835 836 837 838 839 840 841 842 843\n",
      " 844 845 846 847 848 849 850 851 852 853 854 855 856 857 858 859 860 861\n",
      " 862 863 864 865 866 867 868 869 870 871 872 873 874 875 876 877 878 879\n",
      " 880 881 882 883 884 885 886 887 888 889 890]\n",
      "[535 536 537 538 539 540 541 542 543 544 545 546 547 548 549 550 551 552\n",
      " 553 554 555 556 557 558 559 560 561 562 563 564 565 566 567 568 569 570\n",
      " 571 572 573 574 575 576 577 578 579 580 581 582 583 584 585 586 587 588\n",
      " 589 590 591 592 593 594 595 596 597 598 599 600 601 602 603 604 605 606\n",
      " 607 608 609 610 611 612 613 614 615 616 617 618 619 620 621 622 623 624\n",
      " 625 626 627 628 629 630 631 632 633 634 635 636 637 638 639 640 641 642\n",
      " 643 644 645 646 647 648 649 650 651 652 653 654 655 656 657 658 659 660\n",
      " 661 662 663 664 665 666 667 668 669 670 671 672 673 674 675 676 677 678\n",
      " 679 680 681 682 683 684 685 686 687 688 689 690 691 692 693 694 695 696\n",
      " 697 698 699 700 701 702 703 704 705 706 707 708 709 710 711 712]\n",
      "4\n",
      "[  0   1   2   3   4   5   6   7   8   9  10  11  12  13  14  15  16  17\n",
      "  18  19  20  21  22  23  24  25  26  27  28  29  30  31  32  33  34  35\n",
      "  36  37  38  39  40  41  42  43  44  45  46  47  48  49  50  51  52  53\n",
      "  54  55  56  57  58  59  60  61  62  63  64  65  66  67  68  69  70  71\n",
      "  72  73  74  75  76  77  78  79  80  81  82  83  84  85  86  87  88  89\n",
      "  90  91  92  93  94  95  96  97  98  99 100 101 102 103 104 105 106 107\n",
      " 108 109 110 111 112 113 114 115 116 117 118 119 120 121 122 123 124 125\n",
      " 126 127 128 129 130 131 132 133 134 135 136 137 138 139 140 141 142 143\n",
      " 144 145 146 147 148 149 150 151 152 153 154 155 156 157 158 159 160 161\n",
      " 162 163 164 165 166 167 168 169 170 171 172 173 174 175 176 177 178 179\n",
      " 180 181 182 183 184 185 186 187 188 189 190 191 192 193 194 195 196 197\n",
      " 198 199 200 201 202 203 204 205 206 207 208 209 210 211 212 213 214 215\n",
      " 216 217 218 219 220 221 222 223 224 225 226 227 228 229 230 231 232 233\n",
      " 234 235 236 237 238 239 240 241 242 243 244 245 246 247 248 249 250 251\n",
      " 252 253 254 255 256 257 258 259 260 261 262 263 264 265 266 267 268 269\n",
      " 270 271 272 273 274 275 276 277 278 279 280 281 282 283 284 285 286 287\n",
      " 288 289 290 291 292 293 294 295 296 297 298 299 300 301 302 303 304 305\n",
      " 306 307 308 309 310 311 312 313 314 315 316 317 318 319 320 321 322 323\n",
      " 324 325 326 327 328 329 330 331 332 333 334 335 336 337 338 339 340 341\n",
      " 342 343 344 345 346 347 348 349 350 351 352 353 354 355 356 357 358 359\n",
      " 360 361 362 363 364 365 366 367 368 369 370 371 372 373 374 375 376 377\n",
      " 378 379 380 381 382 383 384 385 386 387 388 389 390 391 392 393 394 395\n",
      " 396 397 398 399 400 401 402 403 404 405 406 407 408 409 410 411 412 413\n",
      " 414 415 416 417 418 419 420 421 422 423 424 425 426 427 428 429 430 431\n",
      " 432 433 434 435 436 437 438 439 440 441 442 443 444 445 446 447 448 449\n",
      " 450 451 452 453 454 455 456 457 458 459 460 461 462 463 464 465 466 467\n",
      " 468 469 470 471 472 473 474 475 476 477 478 479 480 481 482 483 484 485\n",
      " 486 487 488 489 490 491 492 493 494 495 496 497 498 499 500 501 502 503\n",
      " 504 505 506 507 508 509 510 511 512 513 514 515 516 517 518 519 520 521\n",
      " 522 523 524 525 526 527 528 529 530 531 532 533 534 535 536 537 538 539\n",
      " 540 541 542 543 544 545 546 547 548 549 550 551 552 553 554 555 556 557\n",
      " 558 559 560 561 562 563 564 565 566 567 568 569 570 571 572 573 574 575\n",
      " 576 577 578 579 580 581 582 583 584 585 586 587 588 589 590 591 592 593\n",
      " 594 595 596 597 598 599 600 601 602 603 604 605 606 607 608 609 610 611\n",
      " 612 613 614 615 616 617 618 619 620 621 622 623 624 625 626 627 628 629\n",
      " 630 631 632 633 634 635 636 637 638 639 640 641 642 643 644 645 646 647\n",
      " 648 649 650 651 652 653 654 655 656 657 658 659 660 661 662 663 664 665\n",
      " 666 667 668 669 670 671 672 673 674 675 676 677 678 679 680 681 682 683\n",
      " 684 685 686 687 688 689 690 691 692 693 694 695 696 697 698 699 700 701\n",
      " 702 703 704 705 706 707 708 709 710 711 712]\n",
      "[713 714 715 716 717 718 719 720 721 722 723 724 725 726 727 728 729 730\n",
      " 731 732 733 734 735 736 737 738 739 740 741 742 743 744 745 746 747 748\n",
      " 749 750 751 752 753 754 755 756 757 758 759 760 761 762 763 764 765 766\n",
      " 767 768 769 770 771 772 773 774 775 776 777 778 779 780 781 782 783 784\n",
      " 785 786 787 788 789 790 791 792 793 794 795 796 797 798 799 800 801 802\n",
      " 803 804 805 806 807 808 809 810 811 812 813 814 815 816 817 818 819 820\n",
      " 821 822 823 824 825 826 827 828 829 830 831 832 833 834 835 836 837 838\n",
      " 839 840 841 842 843 844 845 846 847 848 849 850 851 852 853 854 855 856\n",
      " 857 858 859 860 861 862 863 864 865 866 867 868 869 870 871 872 873 874\n",
      " 875 876 877 878 879 880 881 882 883 884 885 886 887 888 889 890]\n"
     ]
    }
   ],
   "source": [
    "for iter_count, (train_index, test_index) in enumerate(kfold.split(X_titanic_df)):\n",
    "    print(iter_count)\n",
    "    print(train_index)\n",
    "    print(test_index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 3.        ,  1.        , 22.        , ...,  7.25      ,\n",
       "         7.        ,  3.        ],\n",
       "       [ 1.        ,  0.        , 38.        , ..., 71.2833    ,\n",
       "         2.        ,  0.        ],\n",
       "       [ 3.        ,  0.        , 26.        , ...,  7.925     ,\n",
       "         7.        ,  3.        ],\n",
       "       ...,\n",
       "       [ 1.        ,  0.        , 24.        , ..., 49.5042    ,\n",
       "         2.        ,  0.        ],\n",
       "       [ 1.        ,  1.        , 29.69911765, ..., 26.55      ,\n",
       "         2.        ,  3.        ],\n",
       "       [ 1.        ,  1.        , 48.        , ..., 52.        ,\n",
       "         2.        ,  3.        ]])"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_titanic_df.values[train_index]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.svm import SVC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "knn = KNeighborsClassifier(n_neighbors=9)\n",
    "svc = SVC(kernel='linear')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "def exec_kfold(clf, folds = 5):\n",
    "    kfold = KFold(n_splits=folds)\n",
    "    scores = []\n",
    "    \n",
    "    for iter_count, (train_index, test_index) in enumerate(kfold.split(X_titanic_df)):\n",
    "        X_train, X_test = X_titanic_df.values[train_index], X_titanic_df.values[test_index]\n",
    "        y_train, y_test = y_titanic_df.values[train_index], y_titanic_df.values[test_index]\n",
    "        \n",
    "        clf.fit(X_train, y_train)\n",
    "        pred = clf.predict(X_test)\n",
    "        score = accuracy_score(y_test, pred)\n",
    "        print(iter_count,' Accuracy: ', score)\n",
    "        scores.append(score)\n",
    "        \n",
    "    mean_score = np.mean(scores)\n",
    "    print('평균 검증 Accuraccy : ', np.round(mean_score,4))\n",
    "    return mean_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "result = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0  Accuracy:  0.6536312849162011\n",
      "1  Accuracy:  0.7191011235955056\n",
      "2  Accuracy:  0.702247191011236\n",
      "3  Accuracy:  0.702247191011236\n",
      "4  Accuracy:  0.7752808988764045\n",
      "평균 검증 Accuraccy :  0.7105\n"
     ]
    }
   ],
   "source": [
    "max_result = exec_kfold(knn, 5)\n",
    "result.append(max_result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0  Accuracy:  0.5865921787709497\n",
      "1  Accuracy:  0.6685393258426966\n",
      "2  Accuracy:  0.6685393258426966\n",
      "3  Accuracy:  0.6629213483146067\n",
      "4  Accuracy:  0.7078651685393258\n",
      "평균 검증 Accuraccy :  0.6589\n"
     ]
    }
   ],
   "source": [
    "max_result = exec_kfold(svm_svc, 5)\n",
    "result.append(max_result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0  Accuracy:  0.7541899441340782\n",
      "1  Accuracy:  0.7808988764044944\n",
      "2  Accuracy:  0.7865168539325843\n",
      "3  Accuracy:  0.7696629213483146\n",
      "4  Accuracy:  0.8202247191011236\n",
      "평균 검증 Accuraccy :  0.7823\n"
     ]
    }
   ],
   "source": [
    "max_result = exec_kfold(dt_clf, 5)\n",
    "result.append(max_result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0  Accuracy:  0.7932960893854749\n",
      "1  Accuracy:  0.8089887640449438\n",
      "2  Accuracy:  0.8370786516853933\n",
      "3  Accuracy:  0.7752808988764045\n",
      "4  Accuracy:  0.8595505617977528\n",
      "평균 검증 Accuraccy :  0.8148\n"
     ]
    }
   ],
   "source": [
    "max_result = exec_kfold(rf_clf, 5)\n",
    "result.append(max_result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0  Accuracy:  0.8044692737430168\n",
      "1  Accuracy:  0.7808988764044944\n",
      "2  Accuracy:  0.7752808988764045\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:763: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:763: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:763: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:763: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:763: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3  Accuracy:  0.7584269662921348\n",
      "4  Accuracy:  0.8202247191011236\n",
      "평균 검증 Accuraccy :  0.7879\n"
     ]
    }
   ],
   "source": [
    "max_result= exec_kfold(lr_clf, 5)\n",
    "result.append(max_result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "def all_max(all_list):\n",
    "    max_value = 0\n",
    "    index = 0\n",
    "    result = []\n",
    "    for i, model_result in enumerate(all_list):\n",
    "        if(model_result > max_value):\n",
    "            max_value = model_result\n",
    "            index = i\n",
    "        print('현재까지의 max값 >> ' , max_value)\n",
    "    return max_value, index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "현재까지의 max값 >>  0.7105015378821167\n",
      "현재까지의 max값 >>  0.7105015378821167\n",
      "현재까지의 max값 >>  0.782298662984119\n",
      "현재까지의 max값 >>  0.8148389931579938\n",
      "현재까지의 max값 >>  0.8148389931579938\n",
      "(0.8148389931579938, 3)\n"
     ]
    }
   ],
   "source": [
    "max_result = all_max(result)\n",
    "print(max_result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_list = ['KNN','SVC','DecisionTree','Random Forest','Logistic']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "최적의 model은  Random Forest\n"
     ]
    }
   ],
   "source": [
    "print('최적의 model은 ', model_list[max_result[1]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "clf_list = [knn,svm_svc,dt_clf,rf_clf,lr_clf]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "def callKFold_all():\n",
    "    for i in clf_list:\n",
    "        folds = 5\n",
    "        exec_kfold(i, folds)\n",
    "    \n",
    "    max_result = all_max(result)\n",
    "    \n",
    "#     model_list = [DecisionTree','Random Forest','Logistic']\n",
    "    print('최적의 model은 ', model_list[max_result[1]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0  Accuracy:  0.6536312849162011\n",
      "1  Accuracy:  0.7191011235955056\n",
      "2  Accuracy:  0.702247191011236\n",
      "3  Accuracy:  0.702247191011236\n",
      "4  Accuracy:  0.7752808988764045\n",
      "평균 검증 Accuraccy :  0.7105\n",
      "0  Accuracy:  0.5865921787709497\n",
      "1  Accuracy:  0.6685393258426966\n",
      "2  Accuracy:  0.6685393258426966\n",
      "3  Accuracy:  0.6629213483146067\n",
      "4  Accuracy:  0.7078651685393258\n",
      "평균 검증 Accuraccy :  0.6589\n",
      "0  Accuracy:  0.7541899441340782\n",
      "1  Accuracy:  0.7808988764044944\n",
      "2  Accuracy:  0.7865168539325843\n",
      "3  Accuracy:  0.7696629213483146\n",
      "4  Accuracy:  0.8202247191011236\n",
      "평균 검증 Accuraccy :  0.7823\n",
      "0  Accuracy:  0.7932960893854749\n",
      "1  Accuracy:  0.8089887640449438\n",
      "2  Accuracy:  0.8370786516853933\n",
      "3  Accuracy:  0.7752808988764045\n",
      "4  Accuracy:  0.8595505617977528\n",
      "평균 검증 Accuraccy :  0.8148\n",
      "0  Accuracy:  0.8044692737430168\n",
      "1  Accuracy:  0.7808988764044944\n",
      "2  Accuracy:  0.7752808988764045\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:763: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:763: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:763: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:763: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:763: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3  Accuracy:  0.7584269662921348\n",
      "4  Accuracy:  0.8202247191011236\n",
      "평균 검증 Accuraccy :  0.7879\n",
      "현재까지의 max값 >>  0.7105015378821167\n",
      "현재까지의 max값 >>  0.7105015378821167\n",
      "현재까지의 max값 >>  0.782298662984119\n",
      "현재까지의 max값 >>  0.8148389931579938\n",
      "현재까지의 max값 >>  0.8148389931579938\n",
      "최적의 model은  Random Forest\n"
     ]
    }
   ],
   "source": [
    "final_result = callKFold_all()\n",
    "final_result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import cross_val_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "교차 검증 0 정확도: 0.7430\n",
      "교차 검증 1 정확도: 0.7753\n",
      "교차 검증 2 정확도: 0.7921\n",
      "교차 검증 3 정확도: 0.7865\n",
      "교차 검증 4 정확도: 0.8427\n",
      "평균 정확도: 0.7879\n"
     ]
    }
   ],
   "source": [
    "scores = cross_val_score(dt_clf, X_titanic_df, y_titanic_df, cv=5)\n",
    "for iter_count, accuracy in enumerate(scores):\n",
    "    print(\"교차 검증 {0} 정확도: {1:.4f}\".format(iter_count, accuracy))\n",
    "\n",
    "print(\"평균 정확도: {0:.4f}\".format(np.mean(scores)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "def callKFold_all2(clf_list):\n",
    "    for clf in clf_list:\n",
    "        scores = cross_val_score(clf, X_titanic_df, y_titanic_df, cv=5)\n",
    "        for iter_count, accuracy in enumerate(scores):\n",
    "            print(\"교차 검증 {0} 정확도: {1:.4f}\".format(iter_count, accuracy))\n",
    "\n",
    "        print(\"평균 정확도: {0:.4f}\".format(np.mean(scores)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "교차 검증 0 정확도: 0.6480\n",
      "교차 검증 1 정확도: 0.6966\n",
      "교차 검증 2 정확도: 0.6966\n",
      "교차 검증 3 정확도: 0.7247\n",
      "교차 검증 4 정확도: 0.7528\n",
      "평균 정확도: 0.7038\n",
      "교차 검증 0 정확도: 0.6034\n",
      "교차 검증 1 정확도: 0.7135\n",
      "교차 검증 2 정확도: 0.6798\n",
      "교차 검증 3 정확도: 0.6798\n",
      "교차 검증 4 정확도: 0.6854\n",
      "평균 정확도: 0.6724\n",
      "교차 검증 0 정확도: 0.7430\n",
      "교차 검증 1 정확도: 0.7753\n",
      "교차 검증 2 정확도: 0.7921\n",
      "교차 검증 3 정확도: 0.7865\n",
      "교차 검증 4 정확도: 0.8427\n",
      "평균 정확도: 0.7879\n",
      "교차 검증 0 정확도: 0.7933\n",
      "교차 검증 1 정확도: 0.7978\n",
      "교차 검증 2 정확도: 0.8483\n",
      "교차 검증 3 정확도: 0.7640\n",
      "교차 검증 4 정확도: 0.8652\n",
      "평균 정확도: 0.8137\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:763: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:763: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:763: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:763: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:763: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "교차 검증 0 정확도: 0.7989\n",
      "교차 검증 1 정확도: 0.7697\n",
      "교차 검증 2 정확도: 0.7809\n",
      "교차 검증 3 정확도: 0.7753\n",
      "교차 검증 4 정확도: 0.7978\n",
      "평균 정확도: 0.7845\n"
     ]
    }
   ],
   "source": [
    "final_result2 = callKFold_all2(clf_list)\n",
    "final_result2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.74301676, 0.7752809 , 0.79213483, 0.78651685, 0.84269663])"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "numpy.ndarray"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(scores)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "교차 검증 0 정확도: 0.7430\n",
      "교차 검증 1 정확도: 0.7753\n",
      "교차 검증 2 정확도: 0.7921\n",
      "교차 검증 3 정확도: 0.7865\n",
      "교차 검증 4 정확도: 0.8427\n"
     ]
    }
   ],
   "source": [
    "for iter_count, accuracy in enumerate(scores):\n",
    "            print(\"교차 검증 {0} 정확도: {1:.4f}\".format(iter_count, accuracy))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "평균 정확도: 0.7879\n"
     ]
    }
   ],
   "source": [
    "print(\"평균 정확도: {0:.4f}\".format(np.mean(scores)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "####  GridSearchCV를 통해서 최적을 파라메터를 찾아서 참고해보자."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import GridSearchCV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "parameters = {'max_depth':[2,3,5,10], 'min_samples_split':[2,3,5], 'min_samples_leaf':[1,5,8]}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=5, estimator=DecisionTreeClassifier(random_state=11),\n",
       "             param_grid={'max_depth': [2, 3, 5, 10],\n",
       "                         'min_samples_leaf': [1, 5, 8],\n",
       "                         'min_samples_split': [2, 3, 5]},\n",
       "             scoring='accuracy')"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## dt_clf = decisionTree 객체\n",
    "# dt_clf = DecisionTreeClassifier(random_state=11)\n",
    "# rf_clf = RandomForestClassifier(random_state=11)\n",
    "# lr_clf = LogisticRegression()\n",
    "\n",
    "grid_dclf = GridSearchCV(dt_clf, param_grid=parameters, scoring='accuracy', cv=5)\n",
    "grid_dclf.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DecisionTreeClassifier(max_depth=3, min_samples_leaf=5, random_state=11)"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "best_dclf = grid_dclf.best_estimator_\n",
    "best_dclf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'max_depth': 3, 'min_samples_leaf': 5, 'min_samples_split': 2}"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "best_params = grid_dclf.best_params_\n",
    "best_params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7991825076332119"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "best_score = grid_dclf.best_score_\n",
    "best_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1, 0, 0, 0, 0, 0, 0, 1, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 1, 0, 0, 0, 1, 0, 0, 0, 0, 1, 1,\n",
       "       1, 1, 1, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       1, 1, 1, 0, 0, 0, 0, 1, 0, 0, 1, 0, 1, 0, 1, 1, 1, 0, 1, 1, 0, 0,\n",
       "       1, 0, 0, 0, 0, 0, 1, 0, 1, 0, 0, 1, 0, 1, 1, 0, 1, 0, 0, 0, 0, 0,\n",
       "       0, 0, 1, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 1, 0,\n",
       "       1, 0, 1, 0, 1, 0, 0, 1, 1, 0, 0, 0, 0, 1, 0, 0, 1, 0, 0, 1, 1, 0,\n",
       "       1, 1, 0, 0, 1, 1, 0, 1, 0, 1, 0, 1, 1, 0, 0, 1, 0, 1, 0, 0, 0, 0,\n",
       "       0, 0, 0], dtype=int64)"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pred = best_dclf.predict(X_test)\n",
    "pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8715083798882681"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "accuracy = accuracy_score(y_test, pred)\n",
    "accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "#### 테스트 데이터의 스코어보다 예측데이터의 스코어가 높은게 안정적인 설계이다.\n",
    "#### 테스트 데이터 스코어가 높다면 오버피팅된 데이터 이기 때문에.."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "name": "2.6 사이킷런으로 수행하는 타이타닉 생존자 예측 .ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
